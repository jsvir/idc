{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPdvq8+PbU1oZZcaE1RSxGx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "56d5b18d776d496eada0d8abee9cf8bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac59a55eedf1457cb34136046f3fa570",
              "IPY_MODEL_2b90b81985d74db5809f73facae53750",
              "IPY_MODEL_8c19701ab5d24537bd69e645f39b38df"
            ],
            "layout": "IPY_MODEL_9c2d3cd962474b41a8e7175c77114bfd"
          }
        },
        "ac59a55eedf1457cb34136046f3fa570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aff84a29ad044478a7969eeeb9888858",
            "placeholder": "​",
            "style": "IPY_MODEL_f29d904f98e543ecab1d00effc24790c",
            "value": "Epoch 7:  25%"
          }
        },
        "2b90b81985d74db5809f73facae53750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48fe94a533184377b2e233ea29842c0d",
            "max": 81,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94567c77553b4d6d806082283a48864a",
            "value": 20
          }
        },
        "8c19701ab5d24537bd69e645f39b38df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57ea5110abba4014be92736fa45b0c17",
            "placeholder": "​",
            "style": "IPY_MODEL_26c2c1c6ecb04e349645bc50469bd15a",
            "value": " 20/81 [00:05&lt;00:16,  3.74it/s, v_num=0]"
          }
        },
        "9c2d3cd962474b41a8e7175c77114bfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "aff84a29ad044478a7969eeeb9888858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f29d904f98e543ecab1d00effc24790c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48fe94a533184377b2e233ea29842c0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94567c77553b4d6d806082283a48864a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57ea5110abba4014be92736fa45b0c17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26c2c1c6ecb04e349645bc50469bd15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsvir/idc/blob/main/idc_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpretable Deep Clustering (for Tabular Data)\n",
        "\n",
        "You can use **any** data, also images, but for now the model supports only samples similar to table rows: each sample should be a d-dimensional vector.\n",
        "The main goal of our method is to discover clusters assignments for the dataset samples and provide **local** (sample-level) and **global** (cluster-level) interpretations. The interpretations are the feature ids that are have the most important information for clustering and are potentially not representing the data noise.\n",
        "\n",
        "## Model Description:\n",
        "\n",
        "<img src=\"https://github.com/jsvir/idc/tree/main/img/img.png\" width=\"500\">\n",
        "\n",
        "We train a Gating Neural Network together with autoencoder with reconstruction objective while our goal to reconstruct the sample x from the gated version of it (x * z). Then we train the clustering head to discover the clustering of the samples. The last stage is to train the auxiliary classifier that trains the global gates matrix for cluster-level features (interpretations). In addition, we add more sub-steps for training that serve as augmentations to the main stages. We add random binary noise to the input samples, we add noise to the latent embeddings (after encoder) and we start train the autoencoder without gating network.\n",
        "\n",
        "Next, we will go step-by-step with PBMC-2 dataset which is a binary-class subset of the original PBMC [1] dataset. We select two categories that have the most number of samples in the original set. In addition, we remove all zero columns from the data resulting in 17,126 featurees × 20,742 samples size  example to show how the training is done. If you find something unclear, please, let us know.\n",
        "\n",
        "\n",
        "\n",
        "[1] Zheng, G. X., Terry, J. M., Belgrader, P., Ryvkin, P., Bent, Z. W., Wilson, R., Ziraldo, S. B., Wheeler, T. D., McDermott, G. P., Zhu, J., et al. Massively parallel digital transcriptional profiling of single cells. Nature communications, 8(1):14049, 2017."
      ],
      "metadata": {
        "id": "UCKUngg6P3xF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 0: config file definitions\n",
        "\n",
        "| Key                                  | Required / Optional | Example Value                   | Description                                                                                                                                                                                                                                                 |\n",
        "|--------------------------------------|---------------------|---------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| filepath_samples                              | Required            | C:/data/fs/pbmc/pbmc_x.npz      | *Filepath to the npz file with samples table. The table should be of shape [num of samples, num of features]*                                                                                                                                               |\n",
        "| num_clusters                             | Required            | 2                               | *Expected number of clusters*                                                                                                                                                                                                                               |\n",
        "| batch_size                           | Required            | 256                             | *Training and evaluation batch size*                                                                                                                                                                                                                        |\n",
        "| epochs                               | Required            | 200                             | *How many epochs to train the model (total epochs)*                                                                                                                                                                                                         |\n",
        "| seeds                                | Required            | 1                               | *How many random intializations for model re-training*                                                                                                                                                                                                      |\n",
        "| ae_non_gated_epochs                  | Required            | 50                              | *Number of epochs for autoencoder pre-training without gating network.*                                                                                                                                                                                     |\n",
        "| ae_pretrain_epochs                   | Required            | 100                             | *Number of epochs for autoencoder pre-training with gating network.*                                                                                                                                                                                        |\n",
        "| start_global_gates_training_on_epoch | Required            | 150                             | *After this number of epochs we start to train aux. classifier with global gates.*                                                                                                                                                                          |\n",
        "| mask_percentage                      | Required            | 0.9                             | *The random subset of features that will be masked by zero gates. The tuning of this parameter should be based on reconstruction loss convergence. For better convergence try smaller values. Far sparse mask try larger*                                   |\n",
        "| latent_noise_std                     | Required            | 0.01                            | *The std value for random normal noise with mean=1 that multiplies latent embeddings (H) outputed by the encoder.*                                                                                                                                          |\n",
        "| gtcr_loss                            | Optional            | true                            | *Use it to encourge features uniquness at sample-level (the model will try to find the unique set of features for each sample.*                                                                                                                             |\n",
        "| gtcr_projection_dim                  | Optional            | 1024                            | *For large number of features (>10K) it will apply a random projection to the smaller dimension which affects only the GTCR loss*                                                                                                                           |\n",
        "| gtcr_eps                             | Optional            | 1                               | *Code Reduction Rate precision parameter *                                                                                                                                                                                                                  |\n",
        "| eps                                  | Required            | 0.1                             | *Clustering head loss is trained with code reduction rate -based objective with precision parameter. Notice, that here the loss operates on latent embedding and helps to cluster them while gtcr operates on gates only and try to seperate between them.* |\n",
        "| use_gating                           | Required            | true                            | *If trained with Gating Network.*                                                                                                                                                                                                                           |\n",
        "| gates_hidden_dim                     | Required            | 784                             | *The hodden layer dimension in Gating Network.*                                                                                                                                                                                                             |\n",
        "| encdec                               | Required            | [512,512,2048,128,2048,512,512] | *Autoencoder architecture. Each value represents the hidden layer dimension*                                                                                                                                                                                |\n",
        "| clustering_head                      | Required            | [128, 2048]                     | *Clustering head dimension. The input dimension and the hidden dimension.*                                                                                                                                                                                  |\n",
        "| tau                                  | Required            | 100                             | *Tempretaure for GumbleSoftmax. We used a fixed value but you can try also to change it dring the training*                                                                                                                                                 |\n",
        "| aux_classifier                       | Required            | 2048                            | *TThe dimension of the hidden layer in the aux classifier*                                                                                                                                                                                                  |\n",
        "| local_gates_lambda                   | Required            | 1                               | *The weight of the sparsity loss term in the total clustering loss computation.*                                                                                                                                                                            |\n",
        "| global_gates_lambda                  | Required            | 1                               | *The weight of the sparsity loss term in the total aix classifier loss computation.*                                                                                                                                                                        |\n",
        "| gtcr_lambda                          | Required            | 0.01                            | *The weight of the uniqness loss term in the total clustering loss computation.*                                                                                                                                                                            |\n",
        "| lr.pretrain                          | Required            | 1e-3                            | *The learning rate for the autoencoder and gating networks.*                                                                                                                                                                                                |\n",
        "| lr.clustering                        | Required            | 1e-3                            | *The learning rate for the clustering head.*                                                                                                                                                                                                                |\n",
        "| lr.aux_classifier                    | Required            | 1e-1                            | *The learning rate for the aux classifier and global gates matrix.*                                                                                                                                                                                         |\n",
        "| sched.pretrain_min_lr                | Required            | 1e-4                            | *The min learning rate for the autoencoder and gating networks.*                                                                                                                                                                                            |\n",
        "| sched.clustering_min_lr              | Required            | 1e-4                            | *The min learning rate for the clustering head.*                                                                                                                                                                                                            |\n",
        "| save_seed_checkpoints                | Required            | false                           | *Change it to true if you would like to save the checkpoint.*                                                                                                                                                                                               |\n",
        "\n",
        "And finally there are some additional pytorch-lightning configs you should provide but it could remain the same valeus as below:\n",
        "\n",
        "trainer:\n",
        "  devices: 1\n",
        "  accelerator: gpu\n",
        "  max_epochs: *epochs\n",
        "  deterministic: true\n",
        "  logger: true\n",
        "  log_every_n_steps: 10\n",
        "  check_val_every_n_epoch: 10\n",
        "  enable_checkpointing: false\n",
        "  \n",
        "\n",
        "We clone the repo and print the yaml config file we will use for PBMC:"
      ],
      "metadata": {
        "id": "i2DAkrN0RJX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -r idc && git clone https://github.com/jsvir/idc.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtlFRh-JS8ei",
        "outputId": "d578b699-831e-40f8-eed8-83d475aee4f9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'idc': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jsvir/idc.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA__M2t8jJIP",
        "outputId": "74267b72-1ea3-4500-afcf-bda33787bf26"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'idc'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 26 (delta 8), reused 23 (delta 7), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (26/26), 16.65 MiB | 17.03 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd idc && pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "HUHgUvIxiHAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"idc/cfg/cfg_run.yaml\") as f:\n",
        "    for line in f.readlines():\n",
        "        print(line.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GIxCdgwRLCE",
        "outputId": "cb98366c-ab65-4039-bf5c-f352ac54ee4e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filepath_samples: idc/data/pbmc_x.npz\n",
            "num_clusters: 2\n",
            "\n",
            "batch_size: 256\n",
            "seeds: 1\n",
            "epochs: &epochs 200\n",
            "\n",
            "ae_non_gated_epochs: 5 #50\n",
            "ae_pretrain_epochs: 10 #100\n",
            "start_global_gates_training_on_epoch: 150\n",
            "\n",
            "mask_percentage: 0.9\n",
            "latent_noise_std: 0.01\n",
            "\n",
            "trainer:\n",
            "devices: 1\n",
            "accelerator: gpu\n",
            "max_epochs: *epochs\n",
            "deterministic: true\n",
            "logger: true\n",
            "log_every_n_steps: 10\n",
            "check_val_every_n_epoch: 10\n",
            "enable_checkpointing: false\n",
            "num_sanity_val_steps: 0\n",
            "\n",
            "\n",
            "# GTCR loss\n",
            "gtcr_loss: true\n",
            "gtcr_projection_dim: 1024 # for large number of features use it\n",
            "gtcr_eps: 1\n",
            "\n",
            "\n",
            "# Compression loss\n",
            "eps: 0.1\n",
            "\n",
            "# Gating Net\n",
            "use_gating: true\n",
            "gates_hidden_dim: 1024\n",
            "\n",
            "# EncoderDecoder\n",
            "encdec:\n",
            "- 512\n",
            "- 512\n",
            "- 2048\n",
            "- &bn_layer 128\n",
            "- 2048\n",
            "- 512\n",
            "- 512\n",
            "\n",
            "clustering_head:\n",
            "- *bn_layer\n",
            "- 2048\n",
            "\n",
            "tau: 100\n",
            "\n",
            "aux_classifier:\n",
            "- 2048\n",
            "\n",
            "local_gates_lambda: 100\n",
            "global_gates_lambda: 10\n",
            "gtcr_lambda: 0.01\n",
            "\n",
            "lr:\n",
            "pretrain: 1e-3\n",
            "clustering: 1e-3\n",
            "aux_classifier: 1e-1\n",
            "\n",
            "sched:\n",
            "pretrain_min_lr: 1e-4\n",
            "clustering_min_lr: 1e-4\n",
            "\n",
            "save_seed_checkpoints: false\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: data preparation\n",
        "\n",
        "We provide the PBMC-2 dataset in the data directory, unzip it:\n"
      ],
      "metadata": {
        "id": "RH-1MNB7TUOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip idc/data/pbmc_x.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FCCR55qTQ5h",
        "outputId": "d88351fd-7ab3-46ee-9ce4-fea5178c5852"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  idc/data/pbmc_x.zip\n",
            "  inflating: pbmc_x.npz              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: run clustering training\n",
        "\n",
        "We modify the function that plots the clustering to show the plot in the notebook:"
      ],
      "metadata": {
        "id": "3EUJE9p4TbVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"./idc\")\n",
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_clustering(val_embs_list, cluster_mtx, current_epoch, silhouette, dbi):\n",
        "    reducer = umap.UMAP(n_neighbors=10, min_dist=0.1, n_components=2, random_state=0)\n",
        "    embedding = reducer.fit_transform(torch.cat(val_embs_list, dim=0).cpu().numpy())\n",
        "    plt.figure(figsize=(5, 3))\n",
        "    plt.scatter(embedding[:, 0], embedding[:, 1], c=cluster_mtx.numpy(), s=20, edgecolor='k')\n",
        "    plt.title(f'Clustering (UMAP). Epoch: {current_epoch}. Silhouette: {silhouette}. DBI: {dbi}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-wij1ShYTb46"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we train the model.\n",
        "Use these tensorboard commands to show the tensorboard logs in the notebook. Tested on my local machine bit not in Colab."
      ],
      "metadata": {
        "id": "eEndazHTTf5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !tensorboard --logdir logs\\example --port 6006 &"
      ],
      "metadata": {
        "id": "YHEZSrxkToJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorboard import notebook\n",
        "# notebook.list() # View open TensorBoard instances\n",
        "# notebook.display(port=6006, height=1000)"
      ],
      "metadata": {
        "id": "aBOzmwawT21I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYFzpW8DiuAJ",
        "outputId": "7a1871e9-9789-400c-e9ea-ad2e2dc4002b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idc  pbmc_x.npz  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from omegaconf import OmegaConf\n",
        "import numpy as np\n",
        "from pytorch_lightning import Trainer, seed_everything\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor\n",
        "from run import BaseModule\n",
        "\n",
        "\n",
        "cfg = OmegaConf.load(\"idc/cfg/cfg_run.yaml\")\n",
        "cfg.filepath_samples = \"pbmc_x.npz\" # due to colab issues\n",
        "torch.use_deterministic_algorithms(True)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "seed=777\n",
        "cfg.seed = seed\n",
        "seed_everything(seed)\n",
        "np.random.seed(seed)\n",
        "model = BaseModule(cfg)\n",
        "model.plot_clustering = plot_clustering\n",
        "logger = TensorBoardLogger(\"logs\", name=\"example\", log_graph=False)\n",
        "trainer = Trainer(**cfg.trainer, callbacks=[LearningRateMonitor(logging_interval='step')])\n",
        "trainer.logger = logger\n",
        "trainer.fit(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483,
          "referenced_widgets": [
            "56d5b18d776d496eada0d8abee9cf8bb",
            "ac59a55eedf1457cb34136046f3fa570",
            "2b90b81985d74db5809f73facae53750",
            "8c19701ab5d24537bd69e645f39b38df",
            "9c2d3cd962474b41a8e7175c77114bfd",
            "aff84a29ad044478a7969eeeb9888858",
            "f29d904f98e543ecab1d00effc24790c",
            "48fe94a533184377b2e233ea29842c0d",
            "94567c77553b4d6d806082283a48864a",
            "57ea5110abba4014be92736fa45b0c17",
            "26c2c1c6ecb04e349645bc50469bd15a"
          ]
        },
        "id": "hEVDUpjgTgTo",
        "outputId": "efc4bd83-9af2-4943-94fe-d6a02ad63a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape:  (20742, 17126)\n",
            "X.min=0.0, X.max=173.0\n",
            "Dataset length: 20742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: logs/example\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name                | Type                          | Params\n",
            "----------------------------------------------------------------------\n",
            "0 | gating_net          | GatingNet                     | 35.1 M\n",
            "1 | encdec              | EncoderDecoder                | 20.7 M\n",
            "2 | clustering_head     | Sequential                    | 272 K \n",
            "3 | aux_classifier_head | Sequential                    | 35.1 M\n",
            "4 | mcrr                | MaximalCodingRateReduction    | 0     \n",
            "5 | gtcr_loss           | TotalCodingRateWithProjection | 0     \n",
            "----------------------------------------------------------------------\n",
            "91.2 M    Trainable params\n",
            "0         Non-trainable params\n",
            "91.2 M    Total params\n",
            "364.806   Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine annealing LR scheduling is applied during 15390 steps\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56d5b18d776d496eada0d8abee9cf8bb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FF8H7nG0hqcA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}